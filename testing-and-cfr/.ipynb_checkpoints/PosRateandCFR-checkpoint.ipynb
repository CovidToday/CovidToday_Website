{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "5Bg5JGkOoFkM",
    "outputId": "cf9809c3-4877-461c-ee44-6f59c35a2d17"
   },
   "outputs": [],
   "source": [
    "#!pip install wget\n",
    "import sys\n",
    "sys.path.append('/Users/siddharthjain/miniconda3/lib/python3.7/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from scipy.stats.distributions import gamma,lognorm\n",
    "import json \n",
    "import wget\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import pytz \n",
    "from collections import OrderedDict\n",
    "#from google.colab import drive\n",
    "#os.chdir('/content/gdrive/My Drive')\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W81xO0pjosrK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/siddharthjain/Desktop/backend/testing-and-cfr'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir('/content/gdrive/My Drive/test')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GbTAAECqo4b8",
    "outputId": "5f968bf9-90c8-4ce7-d71a-aeef66c10e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(\"test.json\"):\n",
    "    os.remove(\"test.json\")\n",
    "wget.download('https://api.covid19india.org/v3/data-all.json', \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_Mmdu4qo8np"
   },
   "outputs": [],
   "source": [
    "def fn(mon):\n",
    "  if(mon == \"01\"):\n",
    "    return \" January\"\n",
    "  if(mon == \"02\"):\n",
    "    return \" February\"\n",
    "  if(mon == \"03\"):\n",
    "    return \" March\"\n",
    "  if(mon == \"04\"):\n",
    "    return \" April\"\n",
    "  if(mon == \"05\"):\n",
    "    return \" May\"\n",
    "  if(mon == \"06\"):\n",
    "    return \" June\"\n",
    "  if(mon == \"07\"):\n",
    "    return \" July\"\n",
    "  if(mon == \"08\"):\n",
    "    return \" August\"\n",
    "  if(mon == \"09\"):\n",
    "    return \" September\"\n",
    "  if(mon == \"10\"):\n",
    "    return \" October\"\n",
    "  if(mon == \"11\"):\n",
    "    return \" November\"\n",
    "  if(mon == \"12\"):\n",
    "    return \" December\"\n",
    "def convert(dat): \n",
    "    return  str(dat[8:10]) + fn(str(dat[5:7]))\n",
    "def convert1(dat): \n",
    "    return  str(dat[:2]) + fn(str(dat[3:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hx19gK_Vo_5J"
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('./population.csv')\n",
    "population=pd.DataFrame()\n",
    "population[\"State\"]=dataset['State'][:37]\n",
    "population[\"Population\"]=dataset['Population'][:37]\n",
    "population=population.set_index('State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "489_2jZ1pDAe"
   },
   "outputs": [],
   "source": [
    "state_id = {\n",
    "  \"TT\":\"India\",\n",
    "  \"MH\":\"Maharashtra\",\n",
    "  \"TN\":\"Tamil Nadu\",\n",
    "  \"DL\":\"Delhi\",\n",
    "  \"GJ\":\"Gujarat\",\n",
    "  \"RJ\":\"Rajasthan\",\n",
    "  \"UP\":\"Uttar Pradesh\",\n",
    "  \"MP\":\"Madhya Pradesh\",\n",
    "  \"WB\":\"West Bengal\",\n",
    "  \"KA\":\"Karnataka\",\n",
    "  \"BR\":\"Bihar\",\n",
    "  \"AP\":\"Andhra Pradesh\",\n",
    "  \"HR\":\"Haryana\",\n",
    "  \"TG\":\"Telangana\",\n",
    "  \"JK\":\"Jammu and Kashmir\",\n",
    "  \"OR\":\"Odisha\",\n",
    "  \"PB\":\"Punjab\",\n",
    "  \"AS\":\"Assam\",\n",
    "  \"KL\":\"Kerala\",\n",
    "  \"UT\":\"Uttarakhand\",\n",
    "  \"JH\":\"Jharkhand\",\n",
    "  \"CT\":\"Chhattisgarh\",\n",
    "  \"TR\":\"Tripura\",\n",
    "  \"HP\":\"Himachal Pradesh\",\n",
    "  \"CH\":\"Chandigarh\",\n",
    "  \"GA\":\"Goa\",\n",
    "  \"MN\":\"Manipur\",\n",
    "  \"NL\":\"Nagaland\",\n",
    "  \"PY\":\"Puducherry\",\n",
    "  \"LA\":\"Ladakh\",\n",
    "  \"AR\":\"Arunachal Pradesh\",\n",
    "  \"AN\":\"Andaman and Nicobar Islands\",\n",
    "  \"ML\":\"Meghalaya\",\n",
    "  \"MZ\":\"Mizoram\",\n",
    "  \"DN\":\"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "  \"SK\":\"Sikkim\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AmRFhGM1pFYS",
    "outputId": "8b436e87-eb2f-4bf1-a6d9-8f804bc004bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-07-24',\n",
       " '2020-07-25',\n",
       " '2020-07-26',\n",
       " '2020-07-27',\n",
       " '2020-07-28',\n",
       " '2020-07-29',\n",
       " '2020-07-30']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "start=datetime.now()\n",
    "x1=datetime.now(pytz.timezone('Asia/Kolkata')).date()\n",
    "#x1 = datetime.today()\n",
    "#y1 = timedelta(days=7)\n",
    "y1=[]\n",
    "x1=str(x1)[:10]\n",
    "for i in range(7,0,-1):\n",
    "  y1.append(str(datetime.today()-timedelta(days=i))[:10])\n",
    "#print(y1)\n",
    "##y1=str(y1)[:10]\n",
    "t=y1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "4c-wazlDrieU",
    "outputId": "83d71fa0-01a8-4297-b90f-c4a8fefe6b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "Maharashtra\n",
      "Tamil Nadu\n",
      "Delhi\n",
      "Gujarat\n",
      "Rajasthan\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh\n",
      "West Bengal\n",
      "Karnataka\n",
      "Bihar\n",
      "Andhra Pradesh\n",
      "Haryana\n",
      "Telangana\n",
      "Jammu and Kashmir\n",
      "Odisha\n",
      "Punjab\n",
      "Assam\n",
      "Kerala\n",
      "Uttarakhand\n",
      "Jharkhand\n",
      "Chhattisgarh\n",
      "Tripura\n",
      "Himachal Pradesh\n",
      "Chandigarh\n",
      "Goa\n",
      "Manipur\n",
      "Nagaland\n",
      "Puducherry\n",
      "Ladakh\n",
      "Arunachal Pradesh\n",
      "Andaman and Nicobar Islands\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "Sikkim\n",
      "India\n",
      "1\n",
      "Maharashtra\n",
      "1\n",
      "Tamil Nadu\n",
      "1\n",
      "Delhi\n",
      "1\n",
      "Gujarat\n",
      "1\n",
      "Rajasthan\n",
      "1\n",
      "Uttar Pradesh\n",
      "1\n",
      "Madhya Pradesh\n",
      "1\n",
      "West Bengal\n",
      "1\n",
      "Karnataka\n",
      "1\n",
      "Bihar\n",
      "1\n",
      "Andhra Pradesh\n",
      "1\n",
      "Haryana\n",
      "1\n",
      "Telangana\n",
      "1\n",
      "Jammu and Kashmir\n",
      "1\n",
      "Odisha\n",
      "1\n",
      "Punjab\n",
      "1\n",
      "Assam\n",
      "1\n",
      "Kerala\n",
      "1\n",
      "Uttarakhand\n",
      "1\n",
      "Jharkhand\n",
      "1\n",
      "Chhattisgarh\n",
      "1\n",
      "Tripura\n",
      "1\n",
      "Himachal Pradesh\n",
      "1\n",
      "Chandigarh\n",
      "1\n",
      "Goa\n",
      "1\n",
      "Manipur\n",
      "1\n",
      "Nagaland\n",
      "1\n",
      "Puducherry\n",
      "1\n",
      "Ladakh\n",
      "1\n",
      "Arunachal Pradesh\n",
      "1\n",
      "Andaman and Nicobar Islands\n",
      "1\n",
      "Meghalaya\n",
      "1\n",
      "Mizoram\n",
      "1\n",
      "Dadra and Nagar Haveli and Daman and Diu\n",
      "1\n",
      "Sikkim\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "csv_dates=[]\n",
    "csv_states=[]\n",
    "csv_total_cases=[]\n",
    "csv_cum_recovered=[]\n",
    "csv_daily_recovered=[]\n",
    "csv_cum_deceased=[]\n",
    "csv_daily_deceased=[]\n",
    "csv_positivity_rate_cumulative=[]\n",
    "csv_daily_positive_cases=[]\n",
    "csv_daily_positivity_rate=[]\n",
    "csv_daily_positive_cases_ma=[]\n",
    "csv_daily_positivity_rate_ma=[]\n",
    "csv_test_per_million=[]\n",
    "csv_daily_tested=[]\n",
    "csv_cum_tested=[]\n",
    "for x in t:\n",
    "  temp = json.load(open('test.json'))[x]\n",
    "  temp1 = json.load(open('positivity_Rate.json'))\n",
    "  states={}\n",
    "  for j in state_id.keys():\n",
    "    k=state_id[j]\n",
    "    print(k)\n",
    "    test_per_million = temp1[k]['test_per_million']\n",
    "    pos_cum = temp1[k]['cum_positive_cases']\n",
    "    pos_rate_cum = temp1[k]['cum_positivity_rate']\n",
    "    daily_pos = temp1[k]['daily_positive_cases']\n",
    "    daily_pos_ma = temp1[k]['daily_positive_cases_ma']\n",
    "    daily_pos_rate = temp1[k]['daily_positivity_rate']\n",
    "    daily_pos_rate_ma = temp1[k]['daily_positivity_rate_ma']\n",
    "    tested_cum = temp1[k]['cum_tests']\n",
    "    daily_tested = temp1[k]['daily_tests']\n",
    "    deceased_cum = temp1[k]['cum_deceased']\n",
    "    daily_deceased = temp1[k]['daily_deceased']\n",
    "    recovered_cum = temp1[k]['cum_recovered']\n",
    "    daily_recovered = temp1[k]['daily_recovered'] \n",
    "\n",
    "    dates=temp1[k]['dates']\n",
    "    if convert(x) not in dates :\n",
    "      print(1)\n",
    "      dates.append(convert(x))\n",
    "      test_per_million.append('')\n",
    "      pos_cum.append('')\n",
    "      pos_rate_cum.append('')\n",
    "      daily_pos.append('')\n",
    "      daily_pos_ma.append('')\n",
    "      daily_pos_rate.append('')\n",
    "      daily_pos_rate_ma.append('')\n",
    "      tested_cum.append('')\n",
    "      daily_tested.append('')\n",
    "      deceased_cum.append('')\n",
    "      daily_deceased.append('')\n",
    "      recovered_cum.append('')\n",
    "      daily_recovered.append('')\n",
    "      i=len(dates)-1\n",
    "    for l in range(len(dates)):\n",
    "      if convert(x)==dates[l]:\n",
    "        i=l\n",
    "        break\n",
    "    \n",
    "\n",
    "    if k in temp1.keys():\n",
    "        if 'total' in temp[j].keys():\n",
    "          if 'confirmed' in temp[j]['total'].keys():\n",
    "            pos_cum[i]=temp[j]['total']['confirmed']\n",
    "\n",
    "          if 'tested' in temp[j]['total'].keys():\n",
    "            tested_cum[i]=abs(temp[j]['total']['tested'])\n",
    "            test_per_million[i]=temp[j]['total']['tested']*1000000/int(population[\"Population\"][k])\n",
    "              \n",
    "          if 'deceased' in temp[j]['total'].keys():\n",
    "            deceased_cum[i]=temp[j]['total']['deceased']\n",
    "          \n",
    "          if 'recovered' in temp[j]['total'].keys():\n",
    "            recovered_cum[i]=temp[j]['total']['recovered']\n",
    "          \n",
    "          if len(str(pos_cum[i])) and len(str(tested_cum[i])):\n",
    "            pos_rate_cum[i]= pos_cum[i]*100/tested_cum[i]\n",
    "\n",
    "        if 'delta' in temp[j].keys():\n",
    "          if 'confirmed' in temp[j]['delta'].keys():\n",
    "            daily_pos[i]=temp[j]['delta']['confirmed']\n",
    "\n",
    "          if 'tested' in temp[j]['delta'].keys():\n",
    "            daily_tested[i]=abs(temp[j]['delta']['tested'])\n",
    "          \n",
    "          if 'deceased' in temp[j]['delta'].keys():\n",
    "            daily_deceased[i]=temp[j]['delta']['deceased']\n",
    "          \n",
    "          if 'recovered' in temp[j]['delta'].keys():\n",
    "            daily_recovered[i]=temp[j]['delta']['recovered']\n",
    "          \n",
    "          if len(str(daily_pos[i])) and len(str(daily_tested[i])):\n",
    "            daily_pos_rate[i]=int(daily_pos[i])*100/int(daily_tested[i])\n",
    "\n",
    "    for w in range(7,len(daily_pos)):\n",
    "      sum1=0\n",
    "      sum2=0\n",
    "      for s in range(7):\n",
    "        if (len(str(daily_pos[w-s]))!=0 and len(str(daily_tested[w-s]))!=0):\n",
    "          sum1+=int(daily_pos[w-s])\n",
    "          sum2+=int(daily_tested[w-s])\n",
    "      if (sum2!=0):\n",
    "        daily_pos_rate_ma[w]=sum1*100/abs(sum2)\n",
    "    \n",
    "    for w in range(7,len(daily_pos)):\n",
    "      sum1=0\n",
    "      count=0\n",
    "      for s in range(7):\n",
    "        if (len(str(daily_pos[w-s]))!=0):\n",
    "          sum1+=int(daily_pos[w-s])\n",
    "          count+=1\n",
    "      if count!=0:\n",
    "        daily_pos_ma[w]=sum1/count\n",
    "\n",
    "    st=state_id[j]\n",
    "    for i in range(len(dates)):\n",
    "      csv_dates.append(dates[i])\n",
    "      csv_states.append(st)\n",
    "      csv_total_cases.append(pos_cum[i])\n",
    "      csv_positivity_rate_cumulative.append(pos_rate_cum[i])\n",
    "      csv_daily_positive_cases.append(daily_pos[i])\n",
    "      csv_cum_recovered.append(recovered_cum[i])\n",
    "      csv_daily_recovered.append(daily_recovered[i])\n",
    "      csv_cum_deceased.append(deceased_cum[i])\n",
    "      csv_daily_deceased.append(daily_deceased[i])\n",
    "      csv_daily_positivity_rate.append(daily_pos_rate[i])\n",
    "      csv_daily_positive_cases_ma.append(daily_pos_ma[i])\n",
    "      csv_daily_positivity_rate_ma.append(daily_pos_rate_ma[i])\n",
    "      csv_daily_tested.append(daily_tested[i])\n",
    "      csv_cum_tested.append(tested_cum[i])\n",
    "      csv_test_per_million.append(test_per_million[i])\n",
    "    #print(st)\n",
    "    states[st]={\n",
    "                    'dates':dates,\n",
    "                    'cum_positive_cases':pos_cum,\n",
    "                    'cum_positivity_rate':pos_rate_cum,\n",
    "                    'daily_positive_cases':daily_pos,\n",
    "                    'cum_recovered':recovered_cum,\n",
    "                    'daily_recovered':daily_recovered,\n",
    "                    'cum_deceased':deceased_cum,\n",
    "                    'daily_deceased':daily_deceased,\n",
    "                    'daily_positivity_rate':daily_pos_rate,\n",
    "                    'daily_positive_cases_ma': daily_pos_ma,\n",
    "                    'daily_positivity_rate_ma':daily_pos_rate_ma , \n",
    "                    'daily_tests': daily_tested,\n",
    "                    'cum_tests': tested_cum,\n",
    "                    'test_per_million':test_per_million,    \n",
    "              }\n",
    "  states['datetime']=str(datetime.now(pytz.timezone('Asia/Kolkata')))\n",
    "  with open('positivity_Rate.json', 'w') as outfile:\n",
    "    json.dump(states, outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLyUpPIY7Cr0"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['dates']=csv_dates\n",
    "df['state']=csv_states\n",
    "df['cum_positive_cases']=csv_total_cases\n",
    "df['cum_positivity_rate']=csv_positivity_rate_cumulative\n",
    "df['cum_recovered']=csv_cum_recovered\n",
    "df['daily_recovered']:csv_daily_recovered\n",
    "df['cum_deceased']=csv_cum_deceased\n",
    "df['daily_deceased']:daily_deceased\n",
    "df['daily_positive_cases']=csv_daily_positive_cases\n",
    "df['daily_positivity_rate']=csv_daily_positivity_rate\n",
    "df['daily_positive_cases_ma']=csv_daily_positive_cases_ma\n",
    "df['daily_positivity_rate_ma']=    csv_daily_positivity_rate_ma\n",
    "df['daily_tests']=csv_daily_tested\n",
    "df['cum_tested']=csv_cum_tested\n",
    "df['test_per_million']=csv_test_per_million\n",
    "df.to_csv('positivity_Rate.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ye3tsK0SXa9y"
   },
   "source": [
    "## CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlmqEdncXzt2"
   },
   "outputs": [],
   "source": [
    "#dates = np.array([pd.to_datetime(i['date']) for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
    "#print(dates)\n",
    "data_recovered = pd.DataFrame()\n",
    "data_deceased = pd.DataFrame()\n",
    "data_confirmed = pd.DataFrame()\n",
    "for s in state_id.keys():\n",
    "    st=state_id[s]\n",
    "    data_confirmed[st] = np.array(states[st]['daily_positive_cases'])\n",
    "    data_deceased[st] = np.array(states[st]['daily_deceased'])\n",
    "    data_recovered[st] = np.array(states[st]['daily_recovered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xK8aH0zUiL4h"
   },
   "outputs": [],
   "source": [
    "def n2z(x):\n",
    "    x[np.logical_or(np.isnan(x),np.isinf(x))] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YylW_gHIjGaX"
   },
   "outputs": [],
   "source": [
    "data_recovered = data_recovered.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_recovered = data_recovered.astype(np.int32)\n",
    "data_confirmed = data_confirmed.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_confirmed = data_confirmed.astype(np.int32)\n",
    "data_deceased = data_deceased.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_deceased = data_deceased.astype(np.int32)\n",
    "data_deceased['date'] = dates\n",
    "data_recovered['date'] = dates\n",
    "data_confirmed['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "colab_type": "code",
    "id": "z-bxCxt9dKPA",
    "outputId": "b5e096af-207e-4d7e-c266-387c048fe6a1"
   },
   "outputs": [],
   "source": [
    "json_data={}\n",
    "cfr = pd.DataFrame()\n",
    "final=pd.DataFrame\n",
    "plt.figure(1, figsize=(15, 7))\n",
    "for st in state_id.keys():\n",
    "    state=state_id[st]\n",
    "    boots = 100\n",
    "    conf = []\n",
    "    for n in range(boots):\n",
    "        #print(\"Iteration: \",n+1,end='\\r')\n",
    "        dataset = np.copy(data_confirmed[state].values)\n",
    "        mean = 13.0+(20.9-8.7)/4*np.random.normal()\n",
    "        sd = 12.7+(26.0-6.4)/4*np.random.normal()\n",
    "        phi = np.sqrt(sd**2 + mean**2)\n",
    "        mu = np.log(mean**2/phi)\n",
    "        sigma = np.sqrt(np.log(phi**2/mean**2))\n",
    "        L = lognorm(s=sigma,scale=np.exp(mu))\n",
    "        for i in range(len(dataset)-1,-1,-1):\n",
    "            send_forward = np.round(L.rvs(np.max([dataset[i],0])))\n",
    "            send_forward = send_forward[i+send_forward<len(dataset)]\n",
    "            dataset[i] = 0\n",
    "            for j in np.unique(np.int32(send_forward)):\n",
    "                dataset[i+j] += np.sum(send_forward==j)\n",
    "        conf.append(dataset)\n",
    "    CFR = np.cumsum(data_deceased[state].values)/np.cumsum(conf,axis=1)\n",
    "    col_mean = np.nanmean(CFR, axis=0)\n",
    "    inds = np.where(np.isnan(CFR))\n",
    "    CFR[inds] = np.take(col_mean, inds[1])\n",
    "    #temp1=list(pd.Series(dates).dt.strftime('%m-%d-%Y'))\n",
    "    #print(temp1[0])\n",
    "    dates = states[state]['dates']\n",
    "    temp = {\n",
    "        'dates':dates,\n",
    "        'cfr1_point':list(n2z(100*np.cumsum(data_deceased[state].values)/np.cumsum(data_confirmed[state].values))),\n",
    "        'cfr2_point':list(n2z(100*np.cumsum(data_deceased[state].values)/(np.cumsum(data_deceased[state].values)+np.cumsum(data_recovered[state].values)))),\n",
    "        'cfr3_point':list(n2z(100*np.median(CFR,axis=0))),\n",
    "        'cfr3_l95':list(n2z(100*np.quantile(CFR,0.025,axis=0))),\n",
    "        'cfr3_u95':list(n2z(100*np.quantile(CFR,0.975,axis=0))),\n",
    "        'cfr3_l50':list(n2z(100*np.quantile(CFR,0.25,axis=0))),\n",
    "        'cfr3_u50':list(n2z(100*np.quantile(CFR,0.75,axis=0))),\n",
    "        }\n",
    "    a=state_id[st]\n",
    "    #print(a)\n",
    "    json_data[state] = temp\n",
    "    cfr_state=pd.DataFrame()\n",
    "    cfr_state['state']=[str(a)]*len(dates)\n",
    "    cfr_state['dates']=dates\n",
    "    cfr_state['cfr1_point']=(list(100*n2z(np.cumsum(data_deceased[state].values)/np.cumsum(data_confirmed[state].values))))\n",
    "    cfr_state['cfr2_point']=(list(100*n2z(np.cumsum(data_deceased[state].values)/(np.cumsum(data_deceased[state].values)+np.cumsum(data_recovered[state].values)))))\n",
    "    cfr_state['cfr3_point']=(list(100*n2z(np.median(CFR,axis=0))))\n",
    "    cfr_state['cfr3_l95']=(list(100*n2z(np.quantile(CFR,0.025,axis=0))))\n",
    "    cfr_state['cfr3_u95']=(list(100*n2z(np.quantile(CFR,0.975,axis=0))))\n",
    "    cfr_state['cfr3_l50']=(list(100*n2z(np.quantile(CFR,0.25,axis=0))))\n",
    "    cfr_state['cfr3_u50']=(list(100*n2z(np.quantile(CFR,0.75,axis=0))))\n",
    "    cfr=pd.concat([cfr, cfr_state])\n",
    "      \n",
    "    plt.plot(temp['cfr3_point'],label=state)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmm0jRg2ihwc"
   },
   "outputs": [],
   "source": [
    "cfr.to_csv('cfr.csv',index=False)\n",
    "from datetime import datetime\n",
    "json_data['datetime']=str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L71oau76mlox"
   },
   "outputs": [],
   "source": [
    "json_data_indented = json.dumps(json_data, indent = 4)\n",
    "with open(\"cfr.json\", \"w\") as outfile: \n",
    "    outfile.write(json_data_indented)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PosRateNew.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
